{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a102678",
   "metadata": {},
   "source": [
    "# Storage Management with idspy\n",
    "\n",
    "This notebook demonstrates the storage system for organized data persistence and state management. The storage components provide a clean abstraction for handling data persistence across pipeline executions.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "In this tutorial, you'll discover how to:\n",
    "\n",
    "1. **Understanding Storage Interface** - The abstract base class and its contract\n",
    "2. **Use DictStorage** - Simple in-memory storage with dictionary backing\n",
    "3. **Apply Storage Predicates** - Utility functions for checking storage state\n",
    "4. **Implement BindedStorage** - Advanced key mapping and translation\n",
    "5. **Manage Configuration Data** - Storing and retrieving complex settings\n",
    "\n",
    "## Key Benefits\n",
    "\n",
    "- **Abstraction**: Clean interface hiding storage implementation details\n",
    "- **Flexibility**: Swap storage backends without changing pipeline code  \n",
    "- **State Management**: Persist data across pipeline executions\n",
    "- **Key Mapping**: Translate between internal and external key names\n",
    "- **Validation**: Built-in predicates for checking storage state\n",
    "\n",
    "---\n",
    "\n",
    "Let's start by setting up our environment and explore the storage system components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b53c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10216035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.idspy.core.storage.base import Storage, has_key, has_keys, lacks_key, lacks_keys\n",
    "from src.idspy.core.storage.dict import DictStorage\n",
    "from src.idspy.core.storage.proxy import BindedStorage\n",
    "\n",
    "# Sample configuration data for examples\n",
    "sample_config = {\n",
    "    \"model_name\": \"neural_network_v1\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss_function\": \"cross_entropy\"\n",
    "}\n",
    "\n",
    "# Sample metrics data\n",
    "sample_metrics = {\n",
    "    \"accuracy\": 0.95,\n",
    "    \"precision\": 0.92,\n",
    "    \"recall\": 0.89,\n",
    "    \"f1_score\": 0.905\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c39478",
   "metadata": {},
   "source": [
    "## Storage Interface Overview\n",
    "\n",
    "The **Storage** abstract base class defines a consistent interface for all storage implementations. It provides CRUD operations and supports both individual keys and batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fb18ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage Interface Methods:\n",
      "========================================\n",
      "  • as_dict() - Abstract method that must be implemented\n",
      "  • clear() - Abstract method that must be implemented\n",
      "  • delete() - Abstract method that must be implemented\n",
      "  • get() - Abstract method that must be implemented\n",
      "  • has() - Abstract method that must be implemented\n",
      "  • set() - Abstract method that must be implemented\n"
     ]
    }
   ],
   "source": [
    "# Examine the Storage abstract base class methods\n",
    "print(\"Storage Interface Methods:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "abstract_methods = []\n",
    "for method_name in dir(Storage):\n",
    "    if not method_name.startswith('_'):\n",
    "        method = getattr(Storage, method_name)\n",
    "        if hasattr(method, '__isabstractmethod__') and method.__isabstractmethod__:\n",
    "            abstract_methods.append(method_name)\n",
    "\n",
    "for method_name in abstract_methods:\n",
    "    print(f\"  • {method_name}() - Abstract method that must be implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7787b6d6",
   "metadata": {},
   "source": [
    "## DictStorage - Simple In-Memory Storage\n",
    "\n",
    "**DictStorage** is the simplest storage implementation, using a Python dictionary as the backing store. It's perfect for development, testing, and single-session workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e2fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DictStorage instance and demonstrate basic operations\n",
    "storage = DictStorage(sample_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9ca97",
   "metadata": {},
   "source": [
    "### Basic CRUD Operations\n",
    "\n",
    "Demonstrate Create, Read, Update, Delete operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5415c0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved values:\n",
      "  model_name: neural_network_v1\n",
      "  learning_rate: 0.001\n",
      "\n",
      "Note: 'nonexistent_key' is not returned since it doesn't exist\n"
     ]
    }
   ],
   "source": [
    "# GET: Retrieve specific keys\n",
    "retrieved = storage.get([\"model_name\", \"learning_rate\", \"nonexistent_key\"])\n",
    "\n",
    "print(\"Retrieved values:\")\n",
    "for key, value in retrieved.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nNote: 'nonexistent_key' is not returned since it doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7493b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key existence checks:\n",
      "  'model_name': True\n",
      "  'learning_rate': True\n",
      "  'nonexistent_key': False\n"
     ]
    }
   ],
   "source": [
    "# HAS: Check key existence\n",
    "keys_to_check = [\"model_name\", \"learning_rate\", \"nonexistent_key\"]\n",
    "\n",
    "print(\"Key existence checks:\")\n",
    "for key in keys_to_check:\n",
    "    exists = storage.has(key)\n",
    "    print(f\"  '{key}': {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc4d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After updates:\n",
      "  model_name: neural_network_v1\n",
      "  learning_rate: 0.0005 (updated)\n",
      "  batch_size: 32\n",
      "  epochs: 100\n",
      "  optimizer: adam\n",
      "  loss_function: cross_entropy\n",
      "  validation_split: 0.2 (updated)\n",
      "  dropout_rate: 0.3 (updated)\n"
     ]
    }
   ],
   "source": [
    "# UPDATE: Modify existing values and add new ones\n",
    "updates = {\n",
    "    \"learning_rate\": 0.0005,  # Update existing\n",
    "    \"validation_split\": 0.2,  # Add new\n",
    "    \"dropout_rate\": 0.3       # Add new\n",
    "}\n",
    "\n",
    "storage.set(updates)\n",
    "\n",
    "print(\"After updates:\")\n",
    "updated_config = storage.as_dict()\n",
    "for key, value in updated_config.items():\n",
    "    marker = \" (updated)\" if key in updates else \"\"\n",
    "    print(f\"  {key}: {value}{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41a31aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deletion - has 'dropout_rate': True\n",
      "After deletion - has 'dropout_rate': False\n",
      "Current keys: ['model_name', 'learning_rate', 'batch_size', 'epochs', 'optimizer', 'loss_function', 'validation_split']\n"
     ]
    }
   ],
   "source": [
    "# DELETE: Remove specific key\n",
    "print(f\"Before deletion - has 'dropout_rate': {storage.has('dropout_rate')}\")\n",
    "\n",
    "storage.delete('dropout_rate')\n",
    "\n",
    "print(f\"After deletion - has 'dropout_rate': {storage.has('dropout_rate')}\")\n",
    "print(f\"Current keys: {list(storage.as_dict().keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fdcec",
   "metadata": {},
   "source": [
    "### Storage Predicates\n",
    "\n",
    "Use predicate functions to check storage state conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca690d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage predicate tests:\n",
      "  has_key('model_name'): True\n",
      "  has_keys(['model_name', 'learning_rate', 'batch_size']): True\n",
      "  lacks_key('early_stopping'): True\n",
      "  lacks_keys(['validation_split', 'early_stopping']): False\n",
      "\n",
      "Current storage keys: ['model_name', 'learning_rate', 'batch_size', 'epochs', 'optimizer', 'loss_function', 'validation_split']\n"
     ]
    }
   ],
   "source": [
    "# Test various storage predicates\n",
    "required_keys = [\"model_name\", \"learning_rate\", \"batch_size\"]\n",
    "optional_keys = [\"validation_split\", \"early_stopping\"]\n",
    "\n",
    "print(\"Storage predicate tests:\")\n",
    "print(f\"  has_key('model_name'): {has_key('model_name')(storage)}\")\n",
    "print(f\"  has_keys({required_keys}): {has_keys(required_keys)(storage)}\")\n",
    "print(f\"  lacks_key('early_stopping'): {lacks_key('early_stopping')(storage)}\")\n",
    "print(f\"  lacks_keys({optional_keys}): {lacks_keys(optional_keys)(storage)}\")\n",
    "\n",
    "print(f\"\\nCurrent storage keys: {list(storage.as_dict().keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e330499",
   "metadata": {},
   "source": [
    "### Clear Storage\n",
    "\n",
    "Demonstrate clearing all stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ef3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before clear: 7 items\n",
      "After clear: 0 items\n",
      "Storage contents: {}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before clear: {len(storage.as_dict())} items\")\n",
    "\n",
    "storage.clear()\n",
    "\n",
    "print(f\"After clear: {len(storage.as_dict())} items\")\n",
    "print(f\"Storage contents: {storage.as_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d5e10",
   "metadata": {},
   "source": [
    "## BindedStorage with Key Mapping\n",
    "\n",
    "Advanced storage wrapper that translates between external and internal keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18a5e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal storage (abbreviated keys):\n",
      "  mdl_nm: neural_network_v2\n",
      "  lr: 0.002\n",
      "  bs: 64\n",
      "  ep: 150\n",
      "  opt: sgd\n"
     ]
    }
   ],
   "source": [
    "# Create a base storage with internal naming convention\n",
    "internal_storage = DictStorage({\n",
    "    \"mdl_nm\": \"neural_network_v2\",\n",
    "    \"lr\": 0.002,\n",
    "    \"bs\": 64,\n",
    "    \"ep\": 150,\n",
    "    \"opt\": \"sgd\"\n",
    "})\n",
    "\n",
    "print(\"Internal storage (abbreviated keys):\")\n",
    "for key, value in internal_storage.as_dict().items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7dd98",
   "metadata": {},
   "source": [
    "### Key Mapping Configuration\n",
    "\n",
    "Define mappings between user-friendly external keys and internal abbreviated keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75527a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key mappings (external -> internal):\n",
      "  'model_name' -> 'mdl_nm'\n",
      "  'learning_rate' -> 'lr'\n",
      "  'batch_size' -> 'bs'\n",
      "  'epochs' -> 'ep'\n",
      "  'optimizer' -> 'opt'\n"
     ]
    }
   ],
   "source": [
    "# Define key mappings (external -> internal)\n",
    "key_mappings = {\n",
    "    \"model_name\": \"mdl_nm\",\n",
    "    \"learning_rate\": \"lr\",\n",
    "    \"batch_size\": \"bs\",\n",
    "    \"epochs\": \"ep\",\n",
    "    \"optimizer\": \"opt\"\n",
    "}\n",
    "\n",
    "# Create binded storage with key translation\n",
    "binded_storage = BindedStorage(internal_storage, key_mappings, strict=False)\n",
    "\n",
    "print(\"Key mappings (external -> internal):\")\n",
    "for ext, internal in key_mappings.items():\n",
    "    print(f\"  '{ext}' -> '{internal}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e05b1",
   "metadata": {},
   "source": [
    "### External Key Interface\n",
    "\n",
    "Access internal storage using user-friendly external keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ea6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing via external keys:\n",
      "  model_name: neural_network_v2\n",
      "  learning_rate: 0.002\n",
      "  batch_size: 64\n",
      "  epochs: 150\n",
      "  optimizer: sgd\n",
      "\n",
      "Compare with internal storage keys: ['mdl_nm', 'lr', 'bs', 'ep', 'opt']\n"
     ]
    }
   ],
   "source": [
    "# Access data using external (user-friendly) keys\n",
    "print(\"Accessing via external keys:\")\n",
    "external_data = binded_storage.as_dict()\n",
    "for key, value in external_data.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nCompare with internal storage keys: {list(internal_storage.as_dict().keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7909050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved config subset:\n",
      "  model_name: neural_network_v2\n",
      "  learning_rate: 0.002\n",
      "  epochs: 150\n"
     ]
    }
   ],
   "source": [
    "# GET operations using external keys\n",
    "config_subset = binded_storage.get([\"model_name\", \"learning_rate\", \"epochs\"])\n",
    "\n",
    "print(\"Retrieved config subset:\")\n",
    "for key, value in config_subset.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82be86de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After setting new config:\n",
      "External view:\n",
      "  model_name: neural_network_v2\n",
      "  learning_rate: 0.001\n",
      "  batch_size: 128\n",
      "  epochs: 150\n",
      "  optimizer: sgd\n",
      "  momentum: 0.9\n",
      "\n",
      "Internal storage view:\n",
      "  mdl_nm: neural_network_v2\n",
      "  lr: 0.001\n",
      "  bs: 128\n",
      "  ep: 150\n",
      "  opt: sgd\n",
      "  momentum: 0.9\n"
     ]
    }
   ],
   "source": [
    "# SET operations using external keys\n",
    "new_config = {\n",
    "    \"learning_rate\": 0.001,     # Update existing\n",
    "    \"batch_size\": 128,          # Update existing\n",
    "    \"momentum\": 0.9             # Add new (unmapped key)\n",
    "}\n",
    "\n",
    "binded_storage.set(new_config)\n",
    "\n",
    "print(\"After setting new config:\")\n",
    "print(\"External view:\")\n",
    "for key, value in binded_storage.as_dict().items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nInternal storage view:\")\n",
    "for key, value in internal_storage.as_dict().items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7322f",
   "metadata": {},
   "source": [
    "### Key Existence and Deletion\n",
    "\n",
    "Test key existence checks and deletion operations through the binding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f7796f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key existence tests:\n",
      "  'model_name': True\n",
      "  'learning_rate': True\n",
      "  'nonexistent': False\n",
      "  'momentum': True\n"
     ]
    }
   ],
   "source": [
    "# Test key existence with external keys\n",
    "test_keys = [\"model_name\", \"learning_rate\", \"nonexistent\", \"momentum\"]\n",
    "\n",
    "print(\"Key existence tests:\")\n",
    "for key in test_keys:\n",
    "    exists = binded_storage.has(key)\n",
    "    print(f\"  '{key}': {exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0394dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deletion - has 'epochs': True\n",
      "Internal storage has 'ep': True\n",
      "\n",
      "After deletion - has 'epochs': False\n",
      "Internal storage has 'ep': False\n",
      "\n",
      "Remaining keys (external): ['model_name', 'learning_rate', 'batch_size', 'optimizer', 'momentum']\n",
      "Remaining keys (internal): ['mdl_nm', 'lr', 'bs', 'opt', 'momentum']\n"
     ]
    }
   ],
   "source": [
    "# Delete using external key\n",
    "print(f\"Before deletion - has 'epochs': {binded_storage.has('epochs')}\")\n",
    "print(f\"Internal storage has 'ep': {internal_storage.has('ep')}\")\n",
    "\n",
    "binded_storage.delete('epochs')\n",
    "\n",
    "print(f\"\\nAfter deletion - has 'epochs': {binded_storage.has('epochs')}\")\n",
    "print(f\"Internal storage has 'ep': {internal_storage.has('ep')}\")\n",
    "\n",
    "print(f\"\\nRemaining keys (external): {list(binded_storage.as_dict().keys())}\")\n",
    "print(f\"Remaining keys (internal): {list(internal_storage.as_dict().keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335e677",
   "metadata": {},
   "source": [
    "## Strict Mode Key Binding\n",
    "\n",
    "Demonstrate strict key binding that only allows predefined key mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5965bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict mode storage created\n",
      "Available external keys: ['learning_rate', 'batch_size']\n",
      "\n",
      "Accessing 'learning_rate': {'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Create strict binded storage\n",
    "strict_storage = DictStorage({\"lr\": 0.01, \"bs\": 32})\n",
    "strict_mappings = {\"learning_rate\": \"lr\", \"batch_size\": \"bs\"}\n",
    "\n",
    "strict_binded = BindedStorage(strict_storage, strict_mappings, strict=True)\n",
    "\n",
    "print(\"Strict mode storage created\")\n",
    "print(f\"Available external keys: {list(strict_mappings.keys())}\")\n",
    "\n",
    "# This works - using mapped key\n",
    "print(f\"\\nAccessing 'learning_rate': {strict_binded.get(['learning_rate'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64f9c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict mode error: \"Unmapped external key: 'epochs'\"\n",
      "Successfully set mapped key 'learning_rate'\n",
      "Updated value: {'learning_rate': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# This will raise an error in strict mode - using unmapped key\n",
    "try:\n",
    "    strict_binded.set({\"epochs\": 100})  # 'epochs' not in mapping\n",
    "    print(\"Successfully set unmapped key\")\n",
    "except KeyError as e:\n",
    "    print(f\"Strict mode error: {e}\")\n",
    "\n",
    "# This works - using mapped key\n",
    "try:\n",
    "    strict_binded.set({\"learning_rate\": 0.005})\n",
    "    print(\"Successfully set mapped key 'learning_rate'\")\n",
    "    print(f\"Updated value: {strict_binded.get(['learning_rate'])}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd36e5",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Storage Abstraction**: Clean interface that hides implementation details\n",
    "2. **DictStorage**: Simple in-memory storage perfect for development and testing\n",
    "3. **Storage Predicates**: Utility functions for checking storage state and validation\n",
    "4. **BindedStorage**: Advanced wrapper providing key mapping and translation\n",
    "5. **Batch Operations**: Efficient handling of multiple keys simultaneously\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
