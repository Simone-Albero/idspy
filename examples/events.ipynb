{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24043496",
   "metadata": {},
   "source": [
    "# Event Examples\n",
    "\n",
    "This notebook demonstrates the event-driven system for pipeline monitoring, debugging, and observability through immutable events and centralized dispatch.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "- **Event Class**: Immutable event objects with type, ID, constraints, and state\n",
    "- **Event Predicates**: Filtering functions for event matching and selection\n",
    "- **EventBus**: Centralized subscription and dispatching system with priority support\n",
    "- **BaseHandler**: Structured event handling with custom logic and filtering\n",
    "- **ObservablePipeline**: Pipeline integration with automatic event emission\n",
    "- **Error Handling**: Event-driven error tracking and pipeline diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1df2b274806a3f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fcc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e35df280f80fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.476641Z",
     "start_time": "2025-09-03T18:24:07.472412Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.idspy.core.pipeline import PipelineEvent, ObservablePipeline\n",
    "from src.idspy.core.state import State\n",
    "from src.idspy.core.step import Step\n",
    "from src.idspy.events.bus import EventBus, BaseHandler\n",
    "from src.idspy.events.events import Event, only_id, id_startswith, has_constraint_key, constraint_equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9446ea",
   "metadata": {},
   "source": [
    "## Event Class\n",
    "\n",
    "Immutable event objects with type, ID, constraints, and state payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb848ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event as dict: {'type': 'pipeline_step', 'id': 'DataProcessor.Validation', 'constraints': {'requires': ['raw_data', 'schema'], 'provides': ['validated_data'], 'index': 2, 'batch_size': 1000}, 'state': {'raw_data': {'rows': 10000, 'cols': 15}, 'memory_usage': '256MB', 'processing_time': 1.23}, 'timestamp': '2025-09-17T17:29:32.767605+00:00'}\n"
     ]
    }
   ],
   "source": [
    "# Event with complex nested data\n",
    "event = Event(\n",
    "    type=\"pipeline_step\",\n",
    "    id=\"DataProcessor.Validation\",\n",
    "    constraints={\n",
    "        \"requires\": [\"raw_data\", \"schema\"],\n",
    "        \"provides\": [\"validated_data\"],\n",
    "        \"index\": 2,\n",
    "        \"batch_size\": 1000\n",
    "    },\n",
    "    state={\n",
    "        \"raw_data\": {\"rows\": 10000, \"cols\": 15},\n",
    "        \"memory_usage\": \"256MB\",\n",
    "        \"processing_time\": 1.23\n",
    "    }\n",
    ")\n",
    "\n",
    "# Events are immutable - this would raise an error:\n",
    "# event.type = \"different_type\"  # AttributeError!\n",
    "\n",
    "print(f\"Event as dict: {event.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc11838",
   "metadata": {},
   "source": [
    "### Event Predicates\n",
    "\n",
    "Filter functions for event matching: `only_id()`, `id_startswith()`, `has_constraint_key()`, `constraint_equals()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Predicate Examples:\n",
      "========================================\n",
      "Events with ID 'Pipeline.Load':\n",
      "  step_start :: Pipeline.Load\n",
      "  step_end :: Pipeline.Load\n",
      "\n",
      "Events with ID starting with 'Pipeline.':\n",
      "  step_start :: Pipeline.Load\n",
      "  step_start :: Pipeline.Transform\n",
      "  step_end :: Pipeline.Load\n",
      "\n",
      "Events with 'duration' constraint:\n",
      "  step_end :: Pipeline.Load (duration: 1.5)\n",
      "\n",
      "Events with type='input':\n",
      "  step_start :: Pipeline.Load\n"
     ]
    }
   ],
   "source": [
    "# Create some test events\n",
    "events = [\n",
    "    Event(\"step_start\", \"Pipeline.Load\", constraints={\"index\": 0, \"type\": \"input\"}),\n",
    "    Event(\"step_start\", \"Pipeline.Transform\", constraints={\"index\": 1, \"type\": \"processing\"}),\n",
    "    Event(\"step_end\", \"Pipeline.Load\", constraints={\"index\": 0, \"duration\": 1.5}),\n",
    "    Event(\"error\", \"OtherPipeline.Validate\", constraints={\"error_code\": 404}),\n",
    "]\n",
    "\n",
    "print(\"Event Predicate Examples:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test only_id predicate\n",
    "load_predicate = only_id(\"Pipeline.Load\")\n",
    "print(\"Events with ID 'Pipeline.Load':\")\n",
    "for event in filter(load_predicate, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")\n",
    "\n",
    "# Test id_startswith predicate\n",
    "pipeline_predicate = id_startswith(\"Pipeline.\")\n",
    "print(\"\\nEvents with ID starting with 'Pipeline.':\")\n",
    "for event in filter(pipeline_predicate, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")\n",
    "\n",
    "# Test has_constraint_key predicate\n",
    "has_duration = has_constraint_key(\"duration\")\n",
    "print(\"\\nEvents with 'duration' constraint:\")\n",
    "for event in filter(has_duration, events):\n",
    "    print(f\"  {event.type} :: {event.id} (duration: {event.constraints['duration']})\")\n",
    "\n",
    "# Test constraint_equals predicate\n",
    "input_type = constraint_equals(\"type\", \"input\")\n",
    "print(\"\\nEvents with type='input':\")\n",
    "for event in filter(input_type, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec82350ec72c07",
   "metadata": {},
   "source": [
    "## EventBus\n",
    "\n",
    "Centralized event dispatching with subscription patterns and priority control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d98600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing EventBus Subscriptions:\n",
      "========================================\n",
      "\n",
      "Publishing: user_action :: login\n",
      "[USER] Action: authenticate\n",
      "[GLOBAL] user_action from login\n",
      "\n",
      "Publishing: system_event :: maintenance\n",
      "[GLOBAL] system_event from maintenance\n",
      "\n",
      "Publishing: pipeline_step :: Pipeline.Process\n",
      "[MANUAL] pipeline_step\n",
      "[GLOBAL] pipeline_step from Pipeline.Process\n",
      "\n",
      "Publishing: other_event :: misc\n",
      "[GLOBAL] other_event from misc\n",
      "\n",
      "Unsubscribing token 5: True\n",
      "After unsubscription:\n",
      "[GLOBAL] pipeline_step from Pipeline.Another\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate EventBus subscription patterns\n",
    "demo_bus = EventBus()\n",
    "\n",
    "# Pattern 1: Function-based handlers with decorators\n",
    "@demo_bus.on()  # Subscribe to ALL events\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[GLOBAL] {event.type} from {event.id}\")\n",
    "\n",
    "@demo_bus.on(\"user_action\")  # Subscribe to specific event type\n",
    "def user_action_handler(event: Event) -> None:\n",
    "    print(f\"[USER] Action: {event.constraints.get('action', 'unknown')}\")\n",
    "\n",
    "@demo_bus.on(\"system_event\", predicate=has_constraint_key(\"user\"), priority=0)  # With predicate and priority (default 1)\n",
    "def priority_system_handler(event: Event) -> None:\n",
    "    user = event.constraints.get(\"user\")\n",
    "    print(f\"[USER] priority 0 System event for user: {user}\")\n",
    "\n",
    "@demo_bus.on(\"system_event\", predicate=has_constraint_key(\"user\"), priority=2)\n",
    "def priority_system_handler(event: Event) -> None:\n",
    "    user = event.constraints.get(\"user\")\n",
    "    print(f\"[USER] priority 2 System event for user: {user}\")\n",
    "\n",
    "# Pattern 2: Manual subscription with tokens\n",
    "token1 = demo_bus.subscribe(\n",
    "    lambda e: print(f\"[MANUAL] {e.type}\"),\n",
    "    event_type=\"pipeline_step\"\n",
    ")\n",
    "\n",
    "# Test the subscriptions\n",
    "print(\"Testing EventBus Subscriptions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_events = [\n",
    "    Event(\"user_action\", \"login\", constraints={\"action\": \"authenticate\", \"user\": \"alice\"}),\n",
    "    Event(\"system_event\", \"maintenance\", constraints={\"priority\": \"high\", \"duration\": 30}),\n",
    "    Event(\"pipeline_step\", \"Pipeline.Process\", constraints={\"index\": 1}),\n",
    "    Event(\"other_event\", \"misc\", constraints={\"data\": \"test\"}),\n",
    "]\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nPublishing: {event.type} :: {event.id}\")\n",
    "    demo_bus.publish(event)\n",
    "\n",
    "# Demonstrate unsubscription\n",
    "print(f\"\\nUnsubscribing token {token1}: {demo_bus.unsubscribe(token1)}\")\n",
    "print(\"After unsubscription:\")\n",
    "demo_bus.publish(Event(\"pipeline_step\", \"Pipeline.Another\", constraints={\"index\": 2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e085a79",
   "metadata": {},
   "source": [
    "## BaseHandler\n",
    "\n",
    "Structured event handling with custom logic and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c29a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BaseHandler Implementations:\n",
      "==================================================\n",
      "\n",
      "Publishing: before_step :: TestPipeline.Load\n",
      "[MONITOR] TestPipeline starting step 1: TestPipeline.Load\n",
      "\n",
      "Publishing: after_step :: TestPipeline.Load\n",
      "[MONITOR] TestPipeline completed step: TestPipeline.Load\n",
      "\n",
      "Publishing: before_step :: TestPipeline.Process\n",
      "[MONITOR] TestPipeline starting step 2: TestPipeline.Process\n",
      "\n",
      "Publishing: error :: TestPipeline.Process\n",
      "\n",
      "Publishing: after_step :: OtherPipeline.Export\n"
     ]
    }
   ],
   "source": [
    "# Example: Conditional pipeline monitor\n",
    "class PipelineMonitor(BaseHandler):\n",
    "    def __init__(self, pipeline_name: str):\n",
    "        super().__init__()\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.current_step = None\n",
    "        self.step_count = 0\n",
    "\n",
    "    def can_handle(self, event: Event) -> bool:\n",
    "        # Only handle events from our specific pipeline\n",
    "        return event.id.startswith(f\"{self.pipeline_name}.\")\n",
    "\n",
    "    def handle(self, event: Event) -> None:\n",
    "        if event.type == \"before_step\":\n",
    "            self.current_step = event.id\n",
    "            self.step_count += 1\n",
    "            print(f\"[MONITOR] {self.pipeline_name} starting step {self.step_count}: {event.id}\")\n",
    "        elif event.type == \"after_step\":\n",
    "            print(f\"[MONITOR] {self.pipeline_name} completed step: {event.id}\")\n",
    "            self.current_step = None\n",
    "\n",
    "handler_bus = EventBus()\n",
    "pipeline_monitor = PipelineMonitor(\"TestPipeline\")\n",
    "handler_bus.subscribe(pipeline_monitor)\n",
    "\n",
    "# Test with various events\n",
    "test_events = [\n",
    "    Event(\"before_step\", \"TestPipeline.Load\", constraints={\"index\": 0}),\n",
    "    Event(\"after_step\", \"TestPipeline.Load\", constraints={\"index\": 0, \"duration\": 1.2}),\n",
    "    Event(\"before_step\", \"TestPipeline.Process\", constraints={\"index\": 1}),\n",
    "    Event(\"error\", \"TestPipeline.Process\", constraints={\"error\": \"Invalid data format\"}),\n",
    "    Event(\"after_step\", \"OtherPipeline.Export\", constraints={\"index\": 2, \"duration\": 0.8}),\n",
    "]\n",
    "\n",
    "print(\"Testing BaseHandler Implementations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nPublishing: {event.type} :: {event.id}\")\n",
    "    handler_bus.publish(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d57951",
   "metadata": {},
   "source": [
    "## ObservablePipeline\n",
    "\n",
    "Pipeline integration with automatic event emission for monitoring and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c2df733328d40",
   "metadata": {},
   "source": [
    "### Example Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed906bcd8ad3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.504436Z",
     "start_time": "2025-09-03T18:24:07.500944Z"
    }
   },
   "outputs": [],
   "source": [
    "@Step.provides(data=list)\n",
    "class Load(Step):\n",
    "    def run(self, **inputs) -> dict:\n",
    "        return {\"data\": [1, 2, 3]}\n",
    "\n",
    "@Step.requires(data=list)\n",
    "@Step.provides(sum=int)\n",
    "class Sum(Step):\n",
    "    def run(self, data, **inputs) -> dict:\n",
    "        return {\"sum\": sum(data)}\n",
    "\n",
    "@Step.requires(missing=object)\n",
    "class Boom(Step):\n",
    "    def run(self, **inputs) -> dict:\n",
    "        # never reached because requires isn't satisfied\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff07650a76952",
   "metadata": {},
   "source": [
    "### Observable Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15820328ca9184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.513086Z",
     "start_time": "2025-09-03T18:24:07.510094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ObservablePipeline Demo ===\n",
      "[GLOBAL] PipelineEvent.PIPELINE_START from Demo\n",
      "[PipelineEvent.PIPELINE_START] Demo\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from Demo.Load\n",
      "[PipelineEvent.BEFORE_STEP] Demo.Load\n",
      "[GLOBAL] PipelineEvent.AFTER_STEP from Demo.Load\n",
      "[PipelineEvent.AFTER_STEP] Demo.Load\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from Demo.Sum\n",
      "[PipelineEvent.BEFORE_STEP] Demo.Sum\n",
      "[GLOBAL] PipelineEvent.AFTER_STEP from Demo.Sum\n",
      "[PipelineEvent.AFTER_STEP] Demo.Sum\n",
      "[GLOBAL] PipelineEvent.PIPELINE_END from Demo\n",
      "[PipelineEvent.PIPELINE_END] Demo\n",
      "\n",
      "Final STATE: {'data': [1, 2, 3], 'sum': 6}\n"
     ]
    }
   ],
   "source": [
    "# Create and run an ObservablePipeline\n",
    "bus = EventBus()\n",
    "@bus.on(priority=0)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[GLOBAL] {event.type} from {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.PIPELINE_START)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.PIPELINE_END)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.BEFORE_STEP)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.AFTER_STEP)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== ObservablePipeline Demo ===\")\n",
    "p = ObservablePipeline([Load(), Sum()], name=\"Demo\", bus=bus)\n",
    "\n",
    "s = State()\n",
    "p(s)\n",
    "print(f\"\\nFinal STATE: {s.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e250c69aa80ea",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d041f17ee1430d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.527943Z",
     "start_time": "2025-09-03T18:24:07.525462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GLOBAL] PipelineEvent.PIPELINE_START from ErrDemo\n",
      "[PipelineEvent.PIPELINE_START] ErrDemo\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from ErrDemo.Boom\n",
      "[PipelineEvent.BEFORE_STEP] ErrDemo.Boom\n",
      "[GLOBAL] PipelineEvent.ON_ERROR from ErrDemo.Boom\n",
      "[PipelineEvent.ON_ERROR] ErrDemo.Boom\n",
      "[ERROR] ErrDemo.Boom\n",
      "[GLOBAL] PipelineEvent.PIPELINE_END from ErrDemo\n",
      "[PipelineEvent.PIPELINE_END] ErrDemo\n"
     ]
    }
   ],
   "source": [
    "@bus.on(PipelineEvent.ON_ERROR)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[ERROR] {event.id}\")\n",
    "\n",
    "p_err = ObservablePipeline([Boom()], name=\"ErrDemo\", bus=bus)\n",
    "\n",
    "try:\n",
    "    p_err(State())\n",
    "except KeyError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
